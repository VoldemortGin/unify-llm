# UnifyLLM Configuration Example
# Copy this to config.yaml and modify as needed

app:
  name: UnifyLLM
  debug: false
  log_level: INFO

llm:
  # Default LLM parameters
  temperature: 0.7
  max_tokens: 4096
  timeout: 60.0
  max_retries: 3

  # Ollama settings (for local models)
  ollama_base_url: http://localhost:11434
